# God Mode Prompt

Copy this entire prompt and paste it into your AI coding tool (Claude, Cursor, Copilot, etc.) at the start of any Mino project.

````markdown
# Mino API Development Context

You are helping me build a use case with Mino, an AI-powered web automation API by Tinyfish.ai. Mino lets you automate any website using natural language instead of CSS selectors or XPath.

---

## API Reference

### Endpoint
POST https://mino.ai/v1/automation/run-sse

### Authentication
Header: X-API-Key: $MINO_API_KEY

### Request Body
| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| url | string | Yes | Target URL to automate |
| goal | string | Yes | Natural language description of what to do |
| browser_profile | string | No | "lite" (default, fast) or "stealth" (anti-detection) |
| proxy_config | object | No | { enabled: true, country_code: "US" } |

### Supported Proxy Countries
US, GB, CA, DE, FR, JP, AU

### Response (SSE Events)
- type: "STEP" - Progress updates
- type: "COMPLETE" - Final result with resultJson
- type: "ERROR" - Failure information
- streamingUrl - Live browser view URL (valid 24hrs)

---

## Code Template (TypeScript)

```typescript
const response = await fetch("https://mino.ai/v1/automation/run-sse", {
  method: "POST",
  headers: {
    "X-API-Key": process.env.MINO_API_KEY!,
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    url: "https://example.com",
    goal: "Your goal here",
    // Optional:
    // browser_profile: "stealth",
    // proxy_config: { enabled: true, country_code: "US" }
  }),
});

const reader = response.body!.getReader();
const decoder = new TextDecoder();
let buffer = "";

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  buffer += decoder.decode(value, { stream: true });
  const lines = buffer.split("\n");
  buffer = lines.pop() ?? "";

  for (const line of lines) {
    if (line.startsWith("data: ")) {
      const event = JSON.parse(line.slice(6));

      if (event.streamingUrl) {
        console.log("Watch live:", event.streamingUrl);
      }

      if (event.type === "COMPLETE" && event.status === "COMPLETED") {
        return event.resultJson;
      }
    }
  }
}
```

---

## Goal Writing Rules

### DO:
- Be specific: "Extract product name, price, and rating"
- Number steps: "1. Click login 2. Fill email 3. Submit"
- Use visual descriptions: "Click the blue Submit button in the bottom right"
- Specify output format: "Return as JSON array"
- Handle popups: "If cookie banner appears, click Accept"
- Add waits for dynamic content: "Wait 3 seconds for results to load"

### DON'T:
- Be vague: "Get data" or "Extract everything"
- Assume element names: Describe visually instead
- Forget pagination: Specify how many pages to scrape
- Ignore popups: They will block automation

---

## Browser Profile Decision

Use "lite" (default):
- Standard sites without bot protection
- Fast: 3-10 seconds

Use "stealth":
- Sites with Cloudflare, DataDome, CAPTCHAs
- Getting "Access Denied" errors
- Slower: 10-30 seconds

Use stealth + proxy:
- Geo-restricted content
- Persistent blocking even with stealth
- Slowest: 15-45 seconds

---

## Common Patterns

### Login + Extract
```
goal: `
1. Fill email field with "user@example.com"
2. Fill password field with "password123"
3. Click the login button
4. Wait for dashboard to load
5. Extract account balance and recent transactions
`
```

### Pagination
```
goal: `
Navigate through 5 pages by clicking the "Next" button,
extracting product name, price, and URL from each listing.
Return all results combined as a single JSON array.
`
```

### Handle Popups
```
goal: `
If a cookie consent banner appears, click "Accept All".
If a newsletter popup appears, click the X to close it.
Then extract all product names and prices.
`
```

### E-commerce Scraping
```
goal: `
For each product on this page, extract:
- Product name
- Price (including sale price if shown)
- Rating and review count
- Product URL
- Stock status

Return as JSON array.
`
```

---

## Troubleshooting

| Problem | Cause | Solution |
|---------|-------|----------|
| Empty results | Element not found | Watch streamingUrl, use visual descriptions |
| Timeout | Page loads slowly | Add "Wait X seconds" to goal |
| Access Denied | Bot detection | Use stealth mode |
| Still blocked | Heavy protection | Add proxy_config |
| Partial data | Pagination missed | Add pagination instructions |
| Wrong element | Ambiguous description | Be more specific visually |

---

## Debug Checklist

1. Check streamingUrl to watch browser live
2. Simplify goal to isolate the issue
3. Try stealth mode if getting blocked
4. Add proxy if stealth alone doesn't work
5. Add explicit waits for dynamic content
6. Handle any popups that appear

---

## Expected Timing

- Simple extraction: 3-10 seconds
- Multi-step workflow: 30-60 seconds
- Complex with stealth: 1-2 minutes
- With pagination (5+ pages): 2-5 minutes

---

When I describe a use case, help me:
1. Write an effective goal prompt
2. Choose the right browser_profile and proxy settings
3. Structure the code properly
4. Handle edge cases and errors
5. Debug issues using streamingUrl

Always ask clarifying questions if my requirements are unclear.
````
